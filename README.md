# Async Web Scraping


## รายละเอียดโปรเจกต์

โปรเจกต์นี้ใช้:
- **`asyncio`**: สำหรับการรันงานแบบ asynchronous พร้อมกัน
- **`aiohttp`**: สำหรับการทำ HTTP request เพื่อดึงข้อมูลจากหน้าเว็บ
- **`BeautifulSoup`**: สำหรับการแยกและดึงข้อมูล (ในกรณีนี้คือ title ของหน้าเว็บ)
- **`datetime`**: สำหรับการวัดเวลาและแสดงระยะเวลาในการทำงานของแต่ละ URL

## การอธิบายโค้ด

1. **`fetch(session, url)`**: 
   - ทำการร้องขอ HTTP GET แบบ asynchronous ไปยัง URL ที่ระบุ โดยใช้ `session.get()` ของ `aiohttp`
   - คืนค่าผลลัพธ์เป็น HTML ของหน้าเว็บ

2. **`scrape(url)`**:
   - บันทึกเวลาเริ่มต้นก่อนที่จะเริ่มทำการสแครป
   - ดึงข้อมูลเว็บเพจโดยการเรียกใช้ฟังก์ชัน `fetch()`
   - ใช้ `BeautifulSoup` ในการแยก HTML และดึงชื่อเรื่องของหน้าเว็บ (`<title>` tag)
   - บันทึกเวลาเสร็จสิ้นหลังจากประมวลผลข้อมูลแล้ว
   - พิมพ์ชื่อเรื่องของหน้าเว็บและเวลาในการสแครปข้อมูล

3. **`main()`**:
   - กำหนดรายการของ URLs ที่จะสแครป
   - สร้างรายการของ task สำหรับแต่ละ URL เพื่อเรียกฟังก์ชัน `scrape()` แบบ asynchronous โดยใช้ `asyncio.gather()`
   - รัน task ทั้งหมดพร้อมกันแบบ asynchronous เพื่อดึงข้อมูลและประมวลผลเว็บไซต์

## ตัวอย่างผลลัพธ์:
- Title: Attention Required! | Cloudflare  Time taken: 0:00:02.803524 

- Title: หน้าแรก - PSU Intania  คณะวิศวกรรมศาสตร์ มหาวิทยาลัยสงขลานครินทร์ วิทยาเขตหาดใหญ่  Time taken: 0:00:03.081419 

- Title: สาขาวิชาวิศวกรรมคอมพิวเตอร์ - ภาควิชาวิศวกรรมคอมพิวเตอร์  Time taken: 0:00:03.117270 
